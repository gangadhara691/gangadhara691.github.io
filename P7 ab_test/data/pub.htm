<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url('https://themes.googleusercontent.com/fonts/css?kit=dpiI8CyVsrzWsJLBFKehGpLhv3qFjX7dUn1mYxfCXhI');ul.lst-kix_e5x9p2homcwm-5{list-style-type:none}.lst-kix_e5x9p2homcwm-5>li:before{content:"\0025a0  "}.lst-kix_e5x9p2homcwm-6>li:before{content:"\0025cf  "}ul.lst-kix_e5x9p2homcwm-6{list-style-type:none}ul.lst-kix_e5x9p2homcwm-3{list-style-type:none}ul.lst-kix_e5x9p2homcwm-4{list-style-type:none}ul.lst-kix_e5x9p2homcwm-7{list-style-type:none}ul.lst-kix_e5x9p2homcwm-8{list-style-type:none}.lst-kix_e5x9p2homcwm-2>li:before{content:"\0025a0  "}ul.lst-kix_e5x9p2homcwm-1{list-style-type:none}ul.lst-kix_e5x9p2homcwm-2{list-style-type:none}.lst-kix_e5x9p2homcwm-3>li:before{content:"\0025cf  "}.lst-kix_e5x9p2homcwm-4>li:before{content:"\0025cb  "}ul.lst-kix_e5x9p2homcwm-0{list-style-type:none}ul.lst-kix_cy5bhrrouxer-0{list-style-type:none}.lst-kix_93lkjl5r1z4f-1>li:before{content:"\0025cb  "}.lst-kix_e5x9p2homcwm-1>li:before{content:"\0025cb  "}ul.lst-kix_cy5bhrrouxer-2{list-style-type:none}.lst-kix_93lkjl5r1z4f-0>li:before{content:"\0025cf  "}.lst-kix_93lkjl5r1z4f-2>li:before{content:"\0025a0  "}ul.lst-kix_cy5bhrrouxer-1{list-style-type:none}ul.lst-kix_cy5bhrrouxer-4{list-style-type:none}.lst-kix_e5x9p2homcwm-0>li:before{content:"\0025cf  "}ul.lst-kix_cy5bhrrouxer-3{list-style-type:none}ul.lst-kix_cy5bhrrouxer-6{list-style-type:none}ul.lst-kix_cy5bhrrouxer-5{list-style-type:none}.lst-kix_93lkjl5r1z4f-5>li:before{content:"\0025a0  "}.lst-kix_93lkjl5r1z4f-4>li:before{content:"\0025cb  "}.lst-kix_93lkjl5r1z4f-6>li:before{content:"\0025cf  "}.lst-kix_93lkjl5r1z4f-3>li:before{content:"\0025cf  "}.lst-kix_93lkjl5r1z4f-7>li:before{content:"\0025cb  "}.lst-kix_93lkjl5r1z4f-8>li:before{content:"\0025a0  "}.lst-kix_e5x9p2homcwm-7>li:before{content:"\0025cb  "}.lst-kix_e5x9p2homcwm-8>li:before{content:"\0025a0  "}.lst-kix_cy5bhrrouxer-0>li:before{content:"\0025cf  "}ul.lst-kix_cy5bhrrouxer-8{list-style-type:none}ul.lst-kix_cy5bhrrouxer-7{list-style-type:none}.lst-kix_cy5bhrrouxer-5>li:before{content:"\0025a0  "}.lst-kix_cy5bhrrouxer-7>li:before{content:"\0025cb  "}ul.lst-kix_93lkjl5r1z4f-8{list-style-type:none}ul.lst-kix_93lkjl5r1z4f-7{list-style-type:none}.lst-kix_cy5bhrrouxer-4>li:before{content:"\0025cb  "}.lst-kix_cy5bhrrouxer-8>li:before{content:"\0025a0  "}ul.lst-kix_93lkjl5r1z4f-6{list-style-type:none}ul.lst-kix_93lkjl5r1z4f-5{list-style-type:none}ul.lst-kix_93lkjl5r1z4f-4{list-style-type:none}ul.lst-kix_93lkjl5r1z4f-3{list-style-type:none}.lst-kix_cy5bhrrouxer-1>li:before{content:"\0025cb  "}.lst-kix_cy5bhrrouxer-3>li:before{content:"\0025cf  "}ul.lst-kix_93lkjl5r1z4f-2{list-style-type:none}ul.lst-kix_93lkjl5r1z4f-1{list-style-type:none}ul.lst-kix_93lkjl5r1z4f-0{list-style-type:none}.lst-kix_cy5bhrrouxer-2>li:before{content:"\0025a0  "}.lst-kix_cy5bhrrouxer-6>li:before{content:"\0025cf  "}ol{margin:0;padding:0}table td,table th{padding:0}.c5{margin-left:36pt;padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c10{color:#000000;font-weight:400;text-decoration:line-through;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c4{padding-top:8pt;padding-bottom:0pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c7{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:11pt}.c3{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c13{padding-top:10pt;padding-bottom:0pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c6{color:#980000;text-decoration:none;vertical-align:baseline;font-size:13pt;font-family:"Roboto";font-style:normal}.c15{font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c11{color:#666666;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Roboto";font-style:normal}.c8{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c17{font-weight:400;text-decoration:none;vertical-align:baseline;font-size:16pt;font-family:"Roboto";font-style:normal}.c19{background-color:#ffffff;max-width:468pt;padding:14.4pt 72pt 72pt 72pt}.c1{color:inherit;text-decoration:inherit}.c2{color:#1155cc;text-decoration:underline}.c12{color:#980000;vertical-align:sub}.c18{padding:0;margin:0}.c9{background-color:#ffffff;color:#252525}.c0{font-weight:700}.c16{color:#9900ff}.c14{color:#980000}.title{padding-top:0pt;color:#000000;font-size:21pt;padding-bottom:0pt;font-family:"Trebuchet MS";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:13pt;padding-bottom:10pt;font-family:"Trebuchet MS";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:10pt;color:#980000;font-size:16pt;padding-bottom:0pt;font-family:"Roboto";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:8pt;color:#980000;font-weight:700;font-size:13pt;padding-bottom:0pt;font-family:"Roboto";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:8pt;color:#666666;font-weight:700;font-size:12pt;padding-bottom:0pt;font-family:"Roboto";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:8pt;color:#666666;text-decoration:underline;font-size:11pt;padding-bottom:0pt;font-family:"Trebuchet MS";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:8pt;color:#666666;font-size:11pt;padding-bottom:0pt;font-family:"Trebuchet MS";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:8pt;color:#666666;font-size:11pt;padding-bottom:0pt;font-family:"Trebuchet MS";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c19"><h1 class="c13" id="h.1n1oj45gplw4"><span class="c14 c17">Final Project Instructions</span></h1><h2 class="c4" id="h.cdgrnjhqr5ak"><span class="c6 c0">Experiment Overview: Free Trial Screener</span></h2><p class="c8"><span class="c3">At
 the time of this experiment, Udacity courses currently have two options
 on the home page: "start free trial", and "access course materials". If
 the student clicks "start free trial", they will be asked to enter 
their credit card information, and then they will be enrolled in a free 
trial for the paid version of the course. After 14 days, they will 
automatically be charged unless they cancel first. If the student clicks
 "access course materials", they will be able to view the videos and 
take the quizzes for free, but they will not receive coaching support or
 a verified certificate, and they will not submit their final project 
for feedback.</span></p><p class="c7"><span class="c3"></span></p><p class="c8"><span>In
 the experiment, Udacity tested a change where if the student clicked 
"start free trial", they were asked how much time they had available to 
devote to the course. If the student indicated 5 or more hours per week,
 they would be taken through the checkout process as usual. If they 
indicated fewer than 5 hours per week, a message would appear indicating
 that Udacity courses usually require a greater time commitment for 
successful completion, and suggesting that the student might like to 
access the course materials for free. At this point, the student would 
have the option to continue enrolling in the free trial, or access the 
course materials for free instead. </span><span class="c2"><a class="c1" href="https://www.google.com/url?q=https://drive.google.com/a/knowlabs.com/file/d/0ByAfiG8HpNUMakVrS0s4cGN2TjQ/view?usp%3Dsharing&amp;sa=D&amp;ust=1489725305291000&amp;usg=AFQjCNEdiZxdwRnLLAHZcOPDG6ML8qUSyg">This screenshot</a></span><span>&nbsp;shows what the experiment looks like.</span></p><p class="c7"><span class="c3"></span></p><p class="c8"><span>The
 hypothesis was that this might set clearer expectations for students 
upfront, thus reducing the number of frustrated students who left the 
free trial because they didn't have enough time</span><span class="c9">â€”</span><span class="c3">without
 significantly reducing the number of students to continue past the free
 trial and eventually complete the course. If this hypothesis held true,
 Udacity could improve the overall student experience and improve 
coaches' capacity to support students who are likely to complete the 
course.</span></p><p class="c7"><span class="c3"></span></p><p class="c8"><span class="c3">The
 unit of diversion is a cookie, although if the student enrolls in the 
free trial, they are tracked by user-id from that point forward. The 
same user-id cannot enroll in the free trial twice. For users that do 
not enroll, their user-id is not tracked in the experiment, even if they
 were signed in when they visited the course overview page.</span></p><p class="c7"><span class="c3"></span></p><h2 class="c4" id="h.xd75twmqym9z"><span class="c6 c0">Metric Choice</span></h2><p class="c8"><span class="c3">Which
 of the following metrics would you choose to measure for this 
experiment and why? For each metric you choose, indicate whether you 
would use it as an invariant metric or an evaluation metric. The 
practical significance boundary for each metric, that is, the difference
 that would have to be observed before that was a meaningful change for 
the business, is given in parentheses. All practical significance 
boundaries are given as absolute changes.</span></p><p class="c7"><span class="c3"></span></p><p class="c8"><span class="c3">Any
 place "unique cookies" are mentioned, the uniqueness is determined by 
day. (That is, the same cookie visiting on different days would be 
counted twice.) User-ids are automatically unique since the site does 
not allow the same user-id to enroll twice.</span></p><p class="c7"><span class="c3"></span></p><ul class="c18 lst-kix_e5x9p2homcwm-0 start"><li class="c5"><span class="c0">Number of cookies:</span><span>&nbsp;That is, number of unique cookies to view the course overview page. </span><span class="c14">(d</span><span class="c12">min</span><span class="c15 c14">=3000)</span></li><li class="c5"><span class="c0">Number of user-ids:</span><span>&nbsp;That is, number of users who enroll in the free trial. </span><span class="c14">(d</span><span class="c12">min</span><span class="c15 c14">=50)</span></li><li class="c5"><span class="c0">Number of clicks: </span><span>That
 is, number of unique cookies to click the "Start free trial" button 
(which happens before the free trial screener is trigger). </span><span class="c14">(d</span><span class="c12">min</span><span class="c15 c14">=240)</span></li><li class="c5"><span class="c0">Click-through-probability:</span><span>&nbsp;That
 is, number of unique cookies to click the "Start free trial" button 
divided by number of unique cookies to view the course overview page. </span><span class="c14">(d</span><span class="c12">min</span><span class="c15 c14">=0.01)</span></li><li class="c5"><span class="c0">Gross conversion: </span><span>That
 is, number of user-ids to complete checkout and enroll in the free 
trial divided by number of unique cookies to click the "Start free 
trial" button. </span><span class="c14">(d</span><span class="c12">min</span><span class="c15 c14">= 0.01)</span></li><li class="c5"><span class="c0">Retention: </span><span>That
 is, number of user-ids to remain enrolled past the 14-day boundary (and
 thus make at least one payment) divided by number of user-ids to 
complete checkout. </span><span class="c14">(d</span><span class="c12">min</span><span class="c14 c15">=0.01)</span></li><li class="c5"><span class="c0">Net conversion: </span><span>That
 is, number of user-ids to remain enrolled past the 14-day boundary (and
 thus make at least one payment) divided by the number of unique cookies
 to click the "Start free trial" button. </span><span class="c14">(d</span><span class="c12">min</span><span class="c15 c14">= 0.0075)</span></li></ul><p class="c7"><span class="c15 c14"></span></p><p class="c8"><span class="c3">You
 should also decide now what results you will be looking for in order to
 launch the experiment. Would a change in any one of your evaluation 
metrics be sufficient? Would you want to see multiple metrics all move 
or not move at the same time in order to launch? This decision will 
inform your choices while designing the experiment.</span></p><p class="c7"><span class="c3"></span></p><h2 class="c4" id="h.kotwnguf3azx"><span class="c6 c0">Measuring Variability</span></h2><p class="c8"><span class="c2"><a class="c1" href="https://www.google.com/url?q=https://docs.google.com/a/knowlabs.com/spreadsheets/d/1MYNUtC47Pg8hdoCjOXaHqF-thheGpUshrFA21BAJnNc/edit%23gid%3D0&amp;sa=D&amp;ust=1489725305313000&amp;usg=AFQjCNHKp0Vu8jLEetEbQ1OUKoR9dLyEKA">This spreadsheet</a></span><span>&nbsp;contains</span><span>&nbsp;rough
 estimates of the baseline values for these metrics (again, these 
numbers have been changed from Udacity's true numbers).</span></p><p class="c7"><span class="c3"></span></p><p class="c8"><span>For each metric you selected as an evaluation metric</span><span>,</span><span class="c3">&nbsp;estimate
 its standard deviation analytically. Do you expect the analytic 
estimates to be accurate? That is, for which metrics, if any, would you 
want to collect an empirical estimate of the variability if you had 
time?</span></p><p class="c7"><span class="c3"></span></p><h2 class="c4" id="h.ugzgajfjxaua"><span class="c6 c0">Sizing</span></h2><h3 class="c4" id="h.r1z4b6cowjhb"><span class="c0 c11">Choosing Number of Samples given Power</span></h3><p class="c8"><span>Using the analytic estimates of variance, how many pageviews </span><span class="c0">total </span><span>(across both groups) </span><span>would
 you need to collect to adequately power the experiment? Use an alpha of
 0.05 and a beta of 0.2. Make sure you have enough power for </span><span class="c0">each</span><span>&nbsp;metric.</span></p><p class="c7"><span class="c3"></span></p><h3 class="c4" id="h.9ntuec3dr07n"><span class="c11 c0">Choosing Duration vs. Exposure</span></h3><p class="c8"><span class="c3">What
 percentage of Udacity's traffic would you divert to this experiment 
(assuming there were no other experiments you wanted to run 
simultaneously)? Is the change risky enough that you wouldn't want to 
run on all traffic?</span></p><p class="c7"><span class="c3"></span></p><p class="c8"><span class="c3">Given
 the percentage you chose, how long would the experiment take to run, 
using the analytic estimates of variance? If the answer is longer than a
 few weeks, then this is unreasonably long, and you should reconsider an
 earlier decision.</span></p><p class="c7"><span class="c3"></span></p><h2 class="c4" id="h.yq955x15rdtn"><span class="c0 c6">Analysis</span></h2><p class="c8"><span>The data for you to analyze is </span><span class="c2"><a class="c1" href="https://www.google.com/url?q=https://docs.google.com/a/knowlabs.com/spreadsheets/d/1Mu5u9GrybDdska-ljPXyBjTpdZIUev_6i7t4LRDfXM8/edit%23gid%3D0&amp;sa=D&amp;ust=1489725305325000&amp;usg=AFQjCNHtLStKjIhhtVZPMSQvnhqwLpRVvg">here</a></span><span class="c3">.
 This data contains the raw information needed to compute the above 
metrics, broken down day by day. Note that there are two sheets within 
the spreadsheet - one for the experiment group, and one for the control 
group.</span></p><p class="c7"><span class="c3"></span></p><p class="c8"><span class="c3">The meaning of each column is:</span></p><ul class="c18 lst-kix_93lkjl5r1z4f-0 start"><li class="c5"><span class="c0">Pageviews:</span><span class="c3">&nbsp;Number of unique cookies to view the course overview page that day.</span></li><li class="c5"><span class="c0">Clicks: </span><span class="c3">Number of unique cookies to click the course overview page that day.</span></li><li class="c5"><span class="c0">Enrollments: </span><span class="c3">Number of user-ids to enroll in the free trial that day.</span></li><li class="c5"><span class="c0">Payments:</span><span class="c3">&nbsp;Number
 of user-ids who who enrolled on that day to remain enrolled for 14 days
 and thus make a payment. (Note that the date for this column is the 
start date, that is, the date of enrollment, rather than the date of the
 payment. The payment happened 14 days later. Because of this, the 
enrollments and payments are tracked for 14 fewer days than the other 
columns.)</span></li></ul><h3 class="c4" id="h.bbuelyve96gb"><span class="c11 c0">Sanity Checks</span></h3><p class="c8"><span class="c3">Start
 by checking whether your invariant metrics are equivalent between the 
two groups. If the invariant metric is a simple count that should be 
randomly split between the 2 groups, you can use a binomial test as 
demonstrated in Lesson 5. Otherwise, you will need to construct a 
confidence interval for a difference in proportions using a similar 
strategy as in Lesson 1, then check whether the difference between group
 values falls within that confidence level. </span></p><p class="c7"><span class="c3"></span></p><p class="c8"><span class="c3">If your sanity checks fail, look at the day by day data and see if you can offer any insight into what is causing the problem.</span></p><p class="c7"><span class="c3"></span></p><h3 class="c4" id="h.74biaps7z91e"><span class="c11 c0">Check for Practical and Statistical Significance</span></h3><p class="c8"><span class="c3">Next,
 for your evaluation metrics, calculate a confidence interval for the 
difference between the experiment and control groups, and check whether 
each metric is statistically and/or practically significance. A metric 
is statistically significant if the confidence interval does not include
 0 (that is, you can be confident there was a change), and it is 
practically significant if the confidence interval does not include the 
practical significance boundary (that is, you can be confident there is a
 change that matters to the business.)</span></p><p class="c7"><span class="c3"></span></p><p class="c8"><span class="c3">If
 you have chosen multiple evaluation metrics, you will need to decide 
whether to use the Bonferroni correction. When deciding, keep in mind 
the results you are looking for in order to launch the experiment. Will 
the fact that you have multiple metrics make those results more likely 
to occur by chance than the alpha level of 0.05?</span></p><p class="c7"><span class="c3"></span></p><h3 class="c4" id="h.xmm0hn19vvq9"><span class="c11 c0">Run Sign Tests</span></h3><p class="c8"><span class="c3">For
 each evaluation metric, do a sign test using the day-by-day breakdown. 
If the sign test does not agree with the confidence interval for the 
difference, see if you can figure out why.</span></p><p class="c7"><span class="c3"></span></p><h3 class="c4" id="h.wj5g9dw7k8i3"><span class="c11 c0">Make a Recommendation</span></h3><p class="c8"><span class="c3">Finally,
 make a recommendation. Would you launch this experiment, not launch it,
 dig deeper, run a follow-up experiment, or is it a judgment call? If 
you would dig deeper, explain what area you would investigate. If you 
would run follow-up experiments, briefIy describe that experiment. If it
 is a judgment call, explain what factors would be relevant to the 
decision.</span></p><p class="c7"><span class="c3"></span></p><h2 class="c4" id="h.1uci15lndv87"><span class="c6 c0">Follow-Up Experiment: How to Reduce Early Cancellations</span></h2><p class="c8"><span class="c3">If
 you wanted to reduce the number of frustrated students who cancel early
 in the course, what experiment would you try? Give a brief description 
of the change you would make, what your hypothesis would be about the 
effect of the change, what metrics you would want to measure, and what 
unit of diversion you would use. Include an explanation of each of your 
choices.</span></p></body></html>